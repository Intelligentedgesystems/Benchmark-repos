{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet'], 'executed_lines': {1, 2, 4, 5, 7}, 'executed_function_lines': {1}, 'extra_calls': 0}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/__init__.py', 'lineno': 1, 'args': {}, 'lines': ['__version__ = "0.7.1"', 'from .model import EfficientNet, VALID_MODELS'], 'executed_lines': {1, 2}, 'executed_function_lines': {1}, 'extra_calls': 0}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 1, 'args': {}, 'lines': ['"""model.py - Model and module class for EfficientNet.', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from .utils import ('], 'executed_lines': {1, 9, 10, 11, 12}, 'executed_function_lines': {1}, 'extra_calls': 0}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):'], 'executed_lines': {64, 1, 39, 9, 10, 11, 12, 13, 14, 15, 16, 45, 50, 51, 54, 55}, 'executed_function_lines': {64}, 'extra_calls': 0}

{'function_name': 'SwishImplementation', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 64, 'args': {}, 'lines': ['class SwishImplementation(torch.autograd.Function):', '@staticmethod', 'def forward(ctx, i):', '@staticmethod', 'def backward(ctx, grad_output):'], 'executed_lines': {64, 65, 66, 71, 72}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):'], 'executed_lines': {64, 1, 39, 9, 10, 11, 12, 13, 14, 15, 16, 45, 50, 51, 78, 54, 55}, 'executed_function_lines': {64, 78}, 'extra_calls': 0}

{'function_name': 'MemoryEfficientSwish', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 78, 'args': {}, 'lines': ['class MemoryEfficientSwish(nn.Module):', 'def forward(self, x):'], 'executed_lines': {78, 79}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 157, 39, 45, 174, 50, 51, 54, 55, 64, 199, 78, 83, 215, 111}, 'executed_function_lines': {64, 78, 215}, 'extra_calls': 0}

{'function_name': 'Conv2dDynamicSamePadding', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 215, 'args': {}, 'lines': ['class Conv2dDynamicSamePadding(nn.Conv2d):', '"""2D Convolutions like TensorFlow, for a dynamic image size.', 'def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):', 'def forward(self, x):'], 'executed_lines': {216, 232, 236, 215}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):', 'class Conv2dStaticSamePadding(nn.Conv2d):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 157, 39, 45, 174, 50, 51, 54, 55, 64, 199, 78, 83, 215, 111, 248}, 'executed_function_lines': {64, 248, 78, 215}, 'extra_calls': 0}

{'function_name': 'Conv2dStaticSamePadding', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 248, 'args': {}, 'lines': ['class Conv2dStaticSamePadding(nn.Conv2d):', '"""2D Convolutions like TensorFlow\'s \'SAME\' mode, with the given input image size.', 'def __init__(self, in_channels, out_channels, kernel_size, stride=1, image_size=None, **kwargs):', 'def forward(self, x):'], 'executed_lines': {248, 249, 273, 255}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):', 'class Conv2dStaticSamePadding(nn.Conv2d):', 'def get_same_padding_maxPool2d(image_size=None):', 'class MaxPool2dDynamicSamePadding(nn.MaxPool2d):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 279, 157, 39, 295, 45, 174, 50, 51, 54, 55, 64, 199, 78, 83, 215, 111, 248}, 'executed_function_lines': {64, 295, 78, 215, 248}, 'extra_calls': 0}

{'function_name': 'MaxPool2dDynamicSamePadding', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 295, 'args': {}, 'lines': ['class MaxPool2dDynamicSamePadding(nn.MaxPool2d):', '"""2D MaxPooling like TensorFlow\'s \'SAME\' mode, with a dynamic image size.', 'def __init__(self, kernel_size, stride, padding=0, dilation=1, return_indices=False, ceil_mode=False):', 'def forward(self, x):'], 'executed_lines': {296, 306, 300, 295}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):', 'class Conv2dStaticSamePadding(nn.Conv2d):', 'def get_same_padding_maxPool2d(image_size=None):', 'class MaxPool2dDynamicSamePadding(nn.MaxPool2d):', 'class MaxPool2dStaticSamePadding(nn.MaxPool2d):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 279, 157, 39, 295, 45, 174, 50, 51, 54, 55, 319, 64, 199, 78, 83, 215, 111, 248}, 'executed_function_lines': {64, 295, 78, 215, 248, 319}, 'extra_calls': 0}

{'function_name': 'MaxPool2dStaticSamePadding', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 319, 'args': {}, 'lines': ['class MaxPool2dStaticSamePadding(nn.MaxPool2d):', '"""2D MaxPooling like TensorFlow\'s \'SAME\' mode, with the given input image size.', 'def __init__(self, kernel_size, stride, image_size=None, **kwargs):', 'def forward(self, x):'], 'executed_lines': {320, 324, 343, 319}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):', 'class Conv2dStaticSamePadding(nn.Conv2d):', 'def get_same_padding_maxPool2d(image_size=None):', 'class MaxPool2dDynamicSamePadding(nn.MaxPool2d):', 'class MaxPool2dStaticSamePadding(nn.MaxPool2d):', 'class BlockDecoder(object):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 279, 157, 39, 295, 45, 174, 50, 51, 54, 55, 319, 64, 199, 78, 83, 215, 361, 111, 248}, 'executed_function_lines': {64, 295, 361, 78, 215, 248, 319}, 'extra_calls': 0}

{'function_name': 'BlockDecoder', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 361, 'args': {}, 'lines': ['class BlockDecoder(object):', '"""Block Decoder for readability,', '@staticmethod', 'def _decode_block_string(block_string):', '@staticmethod', 'def _encode_block_string(block):', '@staticmethod', 'def decode(string_list):', '@staticmethod', 'def encode(blocks_args):'], 'executed_lines': {361, 362, 425, 426, 366, 367, 401, 402, 441, 442}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 1, 'args': {}, 'lines': ['"""utils.py - Helper functions for building the model and for loading model parameters.', 'import re', 'import math', 'import collections', 'from functools import partial', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from torch.utils import model_zoo', "GlobalParams = collections.namedtuple('GlobalParams', [", "BlockArgs = collections.namedtuple('BlockArgs', [", 'GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)', 'BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)', "if hasattr(nn, 'SiLU'):", 'Swish = nn.SiLU', 'class SwishImplementation(torch.autograd.Function):', 'class MemoryEfficientSwish(nn.Module):', 'def round_filters(filters, global_params):', 'def round_repeats(repeats, global_params):', 'def drop_connect(inputs, p, training):', 'def get_width_and_height_from_size(x):', 'def calculate_output_image_size(input_image_size, stride):', 'def get_same_padding_conv2d(image_size=None):', 'class Conv2dDynamicSamePadding(nn.Conv2d):', 'class Conv2dStaticSamePadding(nn.Conv2d):', 'def get_same_padding_maxPool2d(image_size=None):', 'class MaxPool2dDynamicSamePadding(nn.MaxPool2d):', 'class MaxPool2dStaticSamePadding(nn.MaxPool2d):', 'class BlockDecoder(object):', 'def efficientnet_params(model_name):', 'def efficientnet(width_coefficient=None, depth_coefficient=None, image_size=None,', 'def get_model_params(model_name, override_params):', "'efficientnet-b0': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth',", "'efficientnet-b1': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth',", "'efficientnet-b2': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth',", "'efficientnet-b3': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth',", "'efficientnet-b4': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth',", "'efficientnet-b5': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth',", "'efficientnet-b6': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth',", "'efficientnet-b7': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth',", 'url_map = {', "'efficientnet-b0': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b0-b64d5a18.pth',", "'efficientnet-b1': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b1-0f3ce85a.pth',", "'efficientnet-b2': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b2-6e9d97e5.pth',", "'efficientnet-b3': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b3-cdd7c0f4.pth',", "'efficientnet-b4': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b4-44fb3a87.pth',", "'efficientnet-b5': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b5-86493f6b.pth',", "'efficientnet-b6': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b6-ac80338e.pth',", "'efficientnet-b7': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b7-4652b6dd.pth',", "'efficientnet-b8': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b8-22a8fe65.pth',", 'url_map_advprop = {', 'def load_pretrained_weights(model, model_name, weights_path=None, load_fc=True, advprop=False, verbose=True):'], 'executed_lines': {1, 129, 9, 10, 11, 12, 13, 14, 15, 16, 531, 279, 157, 39, 295, 556, 45, 174, 557, 558, 559, 50, 51, 560, 561, 54, 55, 562, 563, 564, 570, 571, 572, 573, 319, 64, 574, 575, 576, 577, 578, 199, 584, 457, 78, 83, 215, 482, 361, 569, 111, 248}, 'executed_function_lines': {64, 295, 361, 78, 215, 248, 319}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 1, 'args': {}, 'lines': ['"""model.py - Model and module class for EfficientNet.', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from .utils import (', 'VALID_MODELS = (', 'class MBConvBlock(nn.Module):'], 'executed_lines': {1, 36, 9, 10, 11, 12, 26}, 'executed_function_lines': {1, 36}, 'extra_calls': 0}

{'function_name': 'MBConvBlock', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 36, 'args': {}, 'lines': ['class MBConvBlock(nn.Module):', '"""Mobile Inverted Residual Bottleneck Block.', 'def __init__(self, block_args, global_params, image_size=None):', 'def forward(self, inputs, drop_connect_rate=None):', 'def set_swish(self, memory_efficient=True):'], 'executed_lines': {36, 37, 134, 50, 91}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 1, 'args': {}, 'lines': ['"""model.py - Model and module class for EfficientNet.', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from .utils import (', 'VALID_MODELS = (', 'class MBConvBlock(nn.Module):', 'class EfficientNet(nn.Module):'], 'executed_lines': {1, 36, 9, 10, 11, 12, 143, 26}, 'executed_function_lines': {1, 36, 143}, 'extra_calls': 0}

{'function_name': 'EfficientNet', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 143, 'args': {}, 'lines': ['class EfficientNet(nn.Module):', '"""EfficientNet model.', 'def __init__(self, blocks_args=None, global_params=None):', 'def set_swish(self, memory_efficient=True):', 'def extract_endpoints(self, inputs):', 'def extract_features(self, inputs):', 'def forward(self, inputs):', '@classmethod', 'def from_name(cls, model_name, in_channels=3, **override_params):', '@classmethod', 'def from_pretrained(cls, model_name, weights_path=None, advprop=False,', '@classmethod', 'def get_image_size(cls, model_name):', '@classmethod', 'def _check_model_name_is_valid(cls, model_name):', 'def _change_in_channels(self, in_channels):'], 'executed_lines': {384, 163, 323, 324, 231, 349, 397, 143, 144, 303, 398, 278, 410, 348, 221, 383}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'cell'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 1, 'args': {}, 'lines': ['"""model.py - Model and module class for EfficientNet.', 'import torch', 'from torch import nn', 'from torch.nn import functional as F', 'from .utils import (', 'VALID_MODELS = (', 'class MBConvBlock(nn.Module):', 'class EfficientNet(nn.Module):'], 'executed_lines': {1, 36, 9, 10, 11, 12, 143, 26}, 'executed_function_lines': {1, 36, 143}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/__init__.py', 'lineno': 1, 'args': {}, 'lines': ['__version__ = "0.7.1"', 'from .model import EfficientNet, VALID_MODELS', 'from .utils import ('], 'executed_lines': {1, 2, 3}, 'executed_function_lines': {1}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10}, 'executed_function_lines': {1, 383}, 'extra_calls': 0}

{'function_name': 'get_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 383, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ['cls._check_model_name_is_valid(model_name)'], 'executed_lines': {393}, 'executed_function_lines': {397}, 'extra_calls': 0}

{'function_name': '_check_model_name_is_valid', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 397, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ['if model_name not in VALID_MODELS:'], 'executed_lines': {407}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'get_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 383, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ['cls._check_model_name_is_valid(model_name)', '_, _, res, _ = efficientnet_params(model_name)'], 'executed_lines': {393, 394}, 'executed_function_lines': {457, 397}, 'extra_calls': 0}

{'function_name': 'efficientnet_params', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 457, 'args': {'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ["'efficientnet-b0': (1.0, 1.0, 224, 0.2),", "'efficientnet-b1': (1.0, 1.1, 240, 0.2),", "'efficientnet-b2': (1.1, 1.2, 260, 0.3),", "'efficientnet-b3': (1.2, 1.4, 300, 0.3),", "'efficientnet-b4': (1.4, 1.8, 380, 0.4),", "'efficientnet-b5': (1.6, 2.2, 456, 0.4),", "'efficientnet-b6': (1.8, 2.6, 528, 0.5),", "'efficientnet-b7': (2.0, 3.1, 600, 0.5),", "'efficientnet-b8': (2.2, 3.6, 672, 0.5),", "'efficientnet-l2': (4.3, 5.3, 800, 0.5),", 'params_dict = {', 'return params_dict[model_name]'], 'executed_lines': {466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'tuple'>", 'shape': (4,)}}

{'function_name': 'get_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 383, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ['cls._check_model_name_is_valid(model_name)', '_, _, res, _ = efficientnet_params(model_name)', 'return res'], 'executed_lines': {393, 394, 395}, 'executed_function_lines': {457, 397}, 'extra_calls': 0, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)', 'tf.config.experimental_run_functions_eagerly(True)', 'MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]', 'STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]', 'CROP_PADDING = 32', 'image_size = 224', 'def _decode_and_center_crop(image_bytes, image_size):', "tf_img_bytes = tf.io.read_file('examples/simple/img.jpg')", 'tf_img = _decode_and_center_crop(tf_img_bytes, image_size)'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10, 41, 42, 15, 18, 19, 20, 21, 24}, 'executed_function_lines': {24, 1, 383}, 'extra_calls': 0}

{'function_name': '_decode_and_center_crop', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 24, 'args': {'image_bytes': {'type': "<class 'tensorflow.python.framework.ops.EagerTensor'>", 'shape': TensorShape([])}, 'image_size': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['shape = tf.image.extract_jpeg_shape(image_bytes)', 'image_height = shape[0]', 'image_width = shape[1]', 'padded_center_crop_size = tf.cast(', '((image_size / (image_size + CROP_PADDING)) *', 'tf.cast(tf.minimum(image_height, image_width), tf.float32)),', 'tf.int32)', 'offset_height = ((image_height - padded_center_crop_size) + 1) // 2', 'offset_width = ((image_width - padded_center_crop_size) + 1) // 2', 'crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])', 'image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)', 'image = tf.compat.v1.image.resize_bicubic([image], [image_size, image_size])[0]', 'return image'], 'executed_lines': {32, 33, 34, 35, 36, 37, 25, 26, 27, 28, 29, 30, 31}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'tensorflow.python.framework.ops.EagerTensor'>", 'shape': TensorShape([224, 224, 3])}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)', 'tf.config.experimental_run_functions_eagerly(True)', 'MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]', 'STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]', 'CROP_PADDING = 32', 'image_size = 224', 'def _decode_and_center_crop(image_bytes, image_size):', "tf_img_bytes = tf.io.read_file('examples/simple/img.jpg')", 'tf_img = _decode_and_center_crop(tf_img_bytes, image_size)', 'tf_img = tf.compat.v1.image.resize_bicubic([tf_img], [image_size, image_size])[0] # ok it matches up to here', 'use_bfloat16 = 224 # bug in the original repo!', 'tf_img = tf.image.convert_image_dtype(tf_img, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)', 'tf_img = tf.cast(tf_img, tf.float32)', 'tf_img = (tf_img - MEAN_RGB) / (STDDEV_RGB)  # this is exactly the input to the model', 'img = torch.from_numpy(tf_img.numpy()).unsqueeze(0).permute((0,3,1,2))', "labels_map = json.load(open('examples/simple/labels_map.txt'))", 'labels_map = [labels_map[str(i)] for i in range(1000)]'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10, 15, 18, 19, 20, 21, 24, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52}, 'executed_function_lines': {24, 1, 52, 383}, 'extra_calls': 0}

{'function_name': '<listcomp>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 52, 'args': {'.0': {'type': "<class 'range_iterator'>", 'shape': None}}, 'lines': ['labels_map = [labels_map[str(i)] for i in range(1000)]'], 'executed_lines': {52}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (1000,)}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)', 'tf.config.experimental_run_functions_eagerly(True)', 'MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]', 'STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]', 'CROP_PADDING = 32', 'image_size = 224', 'def _decode_and_center_crop(image_bytes, image_size):', "tf_img_bytes = tf.io.read_file('examples/simple/img.jpg')", 'tf_img = _decode_and_center_crop(tf_img_bytes, image_size)', 'tf_img = tf.compat.v1.image.resize_bicubic([tf_img], [image_size, image_size])[0] # ok it matches up to here', 'use_bfloat16 = 224 # bug in the original repo!', 'tf_img = tf.image.convert_image_dtype(tf_img, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)', 'tf_img = tf.cast(tf_img, tf.float32)', 'tf_img = (tf_img - MEAN_RGB) / (STDDEV_RGB)  # this is exactly the input to the model', 'img = torch.from_numpy(tf_img.numpy()).unsqueeze(0).permute((0,3,1,2))', "labels_map = json.load(open('examples/simple/labels_map.txt'))", 'labels_map = [labels_map[str(i)] for i in range(1000)]', 'model = EfficientNet.from_pretrained(model_name)'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10, 15, 18, 19, 20, 21, 24, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55}, 'executed_function_lines': {1, 52, 24, 348, 383}, 'extra_calls': 0}

{'function_name': 'from_pretrained', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 348, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'weights_path': {'type': "<class 'NoneType'>", 'shape': None}, 'advprop': {'type': "<class 'bool'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['model = cls.from_name(model_name, num_classes=num_classes, **override_params)'], 'executed_lines': {377}, 'executed_function_lines': {323}, 'extra_calls': 0}

{'function_name': 'from_name', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 323, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['cls._check_model_name_is_valid(model_name)'], 'executed_lines': {342}, 'executed_function_lines': {397}, 'extra_calls': 0}

{'function_name': '_check_model_name_is_valid', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 397, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ['if model_name not in VALID_MODELS:'], 'executed_lines': {407}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'from_name', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 323, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['cls._check_model_name_is_valid(model_name)', 'blocks_args, global_params = get_model_params(model_name, override_params)'], 'executed_lines': {342, 343}, 'executed_function_lines': {531, 397}, 'extra_calls': 0}

{'function_name': 'get_model_params', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 531, 'args': {'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'override_params': {'type': "<class 'dict'>", 'shape': (1,)}}, 'lines': ["if model_name.startswith('efficientnet'):", 'w, d, s, p = efficientnet_params(model_name)'], 'executed_lines': {541, 542}, 'executed_function_lines': {457}, 'extra_calls': 0}

{'function_name': 'efficientnet_params', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 457, 'args': {'model_name': {'type': "<class 'str'>", 'shape': (15,)}}, 'lines': ["'efficientnet-b0': (1.0, 1.0, 224, 0.2),", "'efficientnet-b1': (1.0, 1.1, 240, 0.2),", "'efficientnet-b2': (1.1, 1.2, 260, 0.3),", "'efficientnet-b3': (1.2, 1.4, 300, 0.3),", "'efficientnet-b4': (1.4, 1.8, 380, 0.4),", "'efficientnet-b5': (1.6, 2.2, 456, 0.4),", "'efficientnet-b6': (1.8, 2.6, 528, 0.5),", "'efficientnet-b7': (2.0, 3.1, 600, 0.5),", "'efficientnet-b8': (2.2, 3.6, 672, 0.5),", "'efficientnet-l2': (4.3, 5.3, 800, 0.5),", 'params_dict = {', 'return params_dict[model_name]'], 'executed_lines': {466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'tuple'>", 'shape': (4,)}}

{'function_name': 'get_model_params', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 531, 'args': {'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'override_params': {'type': "<class 'dict'>", 'shape': (1,)}}, 'lines': ["if model_name.startswith('efficientnet'):", 'w, d, s, p = efficientnet_params(model_name)', 'blocks_args, global_params = efficientnet(', 'width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)'], 'executed_lines': {544, 545, 541, 542}, 'executed_function_lines': {457, 482}, 'extra_calls': 0}

{'function_name': 'efficientnet', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 482, 'args': {'width_coefficient': {'type': "<class 'float'>", 'shape': None}, 'depth_coefficient': {'type': "<class 'float'>", 'shape': None}, 'image_size': {'type': "<class 'int'>", 'shape': None}, 'dropout_rate': {'type': "<class 'float'>", 'shape': None}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}, 'include_top': {'type': "<class 'bool'>", 'shape': None}}, 'lines': ['blocks_args = [', 'blocks_args = BlockDecoder.decode(blocks_args)'], 'executed_lines': {502, 511}, 'executed_function_lines': {425}, 'extra_calls': 0}

{'function_name': 'decode', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 425, 'args': {'string_list': {'type': "<class 'list'>", 'shape': (7,)}}, 'lines': ['assert isinstance(string_list, list)', 'blocks_args = []', 'for block_string in string_list:', 'blocks_args.append(BlockDecoder._decode_block_string(block_string))'], 'executed_lines': {435, 436, 437, 438}, 'executed_function_lines': {366}, 'extra_calls': 0}

{'function_name': '_decode_block_string', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 366, 'args': {'block_string': {'type': "<class 'str'>", 'shape': (27,)}}, 'lines': ['assert isinstance(block_string, str)', "ops = block_string.split('_')", 'options = {}', 'for op in ops:', "splits = re.split(r'(\\d.*)', op)", 'if len(splits) >= 2:', 'key, value = splits[:2]', 'options[key] = value', "assert (('s' in options and len(options['s']) == 1) or", "(len(options['s']) == 2 and options['s'][0] == options['s'][1]))", 'return BlockArgs(', "num_repeat=int(options['r']),", "kernel_size=int(options['k']),", "stride=[int(options['s'][0])],", "expand_ratio=int(options['e']),", "input_filters=int(options['i']),", "output_filters=int(options['o']),", "se_ratio=float(options['se']) if 'se' in options else None,", "id_skip=('noskip' not in block_string))"], 'executed_lines': {384, 385, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 377, 379, 380, 381, 382, 383}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'efficientnet_pytorch.utils.BlockArgs'>", 'shape': (8,)}}

{'function_name': 'decode', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 425, 'args': {'string_list': {'type': "<class 'list'>", 'shape': (7,)}}, 'lines': ['assert isinstance(string_list, list)', 'blocks_args = []', 'for block_string in string_list:', 'blocks_args.append(BlockDecoder._decode_block_string(block_string))', 'assert isinstance(block_string, str)', "ops = block_string.split('_')", 'options = {}', 'for op in ops:', "splits = re.split(r'(\\d.*)', op)", 'if len(splits) >= 2:', 'key, value = splits[:2]', 'options[key] = value', "assert (('s' in options and len(options['s']) == 1) or", "(len(options['s']) == 2 and options['s'][0] == options['s'][1]))", 'return BlockArgs(', "num_repeat=int(options['r']),", "kernel_size=int(options['k']),", "stride=[int(options['s'][0])],", "expand_ratio=int(options['e']),", "input_filters=int(options['i']),", "output_filters=int(options['o']),", "se_ratio=float(options['se']) if 'se' in options else None,", "id_skip=('noskip' not in block_string))", 'return blocks_args'], 'executed_lines': {384, 385, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 435, 436, 437, 438, 439, 377, 379, 380, 381, 382, 383}, 'executed_function_lines': {366}, 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (7,)}}

{'function_name': 'efficientnet', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 482, 'args': {'width_coefficient': {'type': "<class 'float'>", 'shape': None}, 'depth_coefficient': {'type': "<class 'float'>", 'shape': None}, 'image_size': {'type': "<class 'int'>", 'shape': None}, 'dropout_rate': {'type': "<class 'float'>", 'shape': None}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}, 'include_top': {'type': "<class 'bool'>", 'shape': None}}, 'lines': ['blocks_args = [', 'blocks_args = BlockDecoder.decode(blocks_args)', 'global_params = GlobalParams(', 'width_coefficient=width_coefficient,', 'depth_coefficient=depth_coefficient,', 'image_size=image_size,', 'dropout_rate=dropout_rate,', 'num_classes=num_classes,', 'batch_norm_momentum=0.99,', 'batch_norm_epsilon=1e-3,', 'drop_connect_rate=drop_connect_rate,', 'depth_divisor=8,', 'min_depth=None,', 'include_top=include_top,', 'return blocks_args, global_params'], 'executed_lines': {513, 514, 515, 516, 517, 519, 520, 521, 522, 523, 524, 525, 528, 502, 511}, 'executed_function_lines': {425}, 'extra_calls': 0, 'return_value': {'type': "<class 'tuple'>", 'shape': (2,)}}

{'function_name': 'get_model_params', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 531, 'args': {'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'override_params': {'type': "<class 'dict'>", 'shape': (1,)}}, 'lines': ["if model_name.startswith('efficientnet'):", 'w, d, s, p = efficientnet_params(model_name)', 'blocks_args, global_params = efficientnet(', 'width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)', 'if override_params:', 'global_params = global_params._replace(**override_params)', 'return blocks_args, global_params'], 'executed_lines': {544, 545, 548, 550, 551, 541, 542}, 'executed_function_lines': {457, 482}, 'extra_calls': 0, 'return_value': {'type': "<class 'tuple'>", 'shape': (2,)}}

{'function_name': 'from_name', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 323, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['cls._check_model_name_is_valid(model_name)', 'blocks_args, global_params = get_model_params(model_name, override_params)', 'model = cls(blocks_args, global_params)'], 'executed_lines': {344, 342, 343}, 'executed_function_lines': {163, 531, 397}, 'extra_calls': 0}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176}, 'executed_function_lines': {199}, 'extra_calls': 0}

{'function_name': 'get_same_padding_conv2d', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 199, 'args': {'image_size': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if image_size is None:', 'return partial(Conv2dStaticSamePadding, image_size=image_size)'], 'executed_lines': {209, 212}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'functools.partial'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180}, 'executed_function_lines': {83, 199}, 'extra_calls': 0}

{'function_name': 'round_filters', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 83, 'args': {'filters': {'type': "<class 'int'>", 'shape': None}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['multiplier = global_params.width_coefficient', 'if not multiplier:', 'divisor = global_params.depth_divisor', 'min_depth = global_params.min_depth', 'filters *= multiplier', 'min_depth = min_depth or divisor  # pay attention to this line when using min_depth', 'new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)', 'if new_filters < 0.9 * filters:  # prevent rounding by more than 10%', 'return int(new_filters)'], 'executed_lines': {100, 101, 102, 103, 105, 106, 108, 94, 95}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180, 181}, 'executed_function_lines': {255, 83, 199}, 'extra_calls': 0}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 255, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.Conv2dStaticSamePadding'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'out_channels': {'type': "<class 'int'>", 'shape': None}, 'kernel_size': {'type': "<class 'int'>", 'shape': None}, 'stride': {'type': "<class 'int'>", 'shape': None}, 'image_size': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)', 'self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2', 'assert image_size is not None', 'ih, iw = (image_size, image_size) if isinstance(image_size, int) else image_size', 'kh, kw = self.weight.size()[-2:]', 'sh, sw = self.stride', 'oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)', 'pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)', 'pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)', 'if pad_h > 0 or pad_w > 0:', 'self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,', 'pad_h // 2, pad_h - pad_h // 2))'], 'executed_lines': {256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)', 'self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'image_size = calculate_output_image_size(image_size, 2)'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180, 181, 182, 183}, 'executed_function_lines': {255, 83, 174, 199}, 'extra_calls': 0}

{'function_name': 'calculate_output_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 174, 'args': {'input_image_size': {'type': "<class 'int'>", 'shape': None}, 'stride': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if input_image_size is None:', 'image_height, image_width = get_width_and_height_from_size(input_image_size)'], 'executed_lines': {185, 187}, 'executed_function_lines': {157}, 'extra_calls': 0}

{'function_name': 'get_width_and_height_from_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 157, 'args': {'x': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if isinstance(x, int):', 'return x, x'], 'executed_lines': {166, 167}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'tuple'>", 'shape': (2,)}}

{'function_name': 'calculate_output_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 174, 'args': {'input_image_size': {'type': "<class 'int'>", 'shape': None}, 'stride': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if input_image_size is None:', 'image_height, image_width = get_width_and_height_from_size(input_image_size)', 'stride = stride if isinstance(stride, int) else stride[0]', 'image_height = int(math.ceil(image_height / stride))', 'image_width = int(math.ceil(image_width / stride))', 'return [image_height, image_width]'], 'executed_lines': {185, 187, 188, 189, 190, 191}, 'executed_function_lines': {157}, 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (2,)}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)', 'self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'image_size = calculate_output_image_size(image_size, 2)', 'self._blocks = nn.ModuleList([])', 'for block_args in self._blocks_args:', 'block_args = block_args._replace(', 'input_filters=round_filters(block_args.input_filters, self._global_params),', 'multiplier = global_params.width_coefficient', 'if not multiplier:', 'divisor = global_params.depth_divisor', 'min_depth = global_params.min_depth', 'filters *= multiplier', 'min_depth = min_depth or divisor  # pay attention to this line when using min_depth', 'new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)', 'if new_filters < 0.9 * filters:  # prevent rounding by more than 10%', 'return int(new_filters)', 'output_filters=round_filters(block_args.output_filters, self._global_params),', 'num_repeat=round_repeats(block_args.num_repeat, self._global_params)'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180, 181, 182, 183, 186, 187, 190, 191, 192, 193, 94, 95, 100, 101, 102, 103, 105, 106, 108}, 'executed_function_lines': {199, 174, 111, 83, 255}, 'extra_calls': 0, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': 'round_repeats', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 111, 'args': {'repeats': {'type': "<class 'int'>", 'shape': None}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['multiplier = global_params.depth_coefficient', 'if not multiplier:', 'return int(math.ceil(multiplier * repeats))'], 'executed_lines': {122, 123, 126}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)', 'self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'image_size = calculate_output_image_size(image_size, 2)', 'self._blocks = nn.ModuleList([])', 'for block_args in self._blocks_args:', 'block_args = block_args._replace(', 'input_filters=round_filters(block_args.input_filters, self._global_params),', 'multiplier = global_params.width_coefficient', 'if not multiplier:', 'divisor = global_params.depth_divisor', 'min_depth = global_params.min_depth', 'filters *= multiplier', 'min_depth = min_depth or divisor  # pay attention to this line when using min_depth', 'new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)', 'if new_filters < 0.9 * filters:  # prevent rounding by more than 10%', 'return int(new_filters)', 'output_filters=round_filters(block_args.output_filters, self._global_params),', 'num_repeat=round_repeats(block_args.num_repeat, self._global_params)', 'self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180, 181, 182, 183, 186, 187, 190, 191, 192, 193, 197, 94, 95, 100, 101, 102, 103, 105, 106, 108}, 'executed_function_lines': {199, 174, 111, 50, 83, 255}, 'extra_calls': 0, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 50, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'block_args': {'type': "<class 'efficientnet_pytorch.utils.BlockArgs'>", 'shape': (8,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}, 'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['super().__init__()', 'self._block_args = block_args', "self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow", 'self._bn_eps = global_params.batch_norm_epsilon', 'self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)', 'self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect', 'inp = self._block_args.input_filters  # number of input channels', 'oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels', 'if self._block_args.expand_ratio != 1:', 'k = self._block_args.kernel_size', 's = self._block_args.stride', 'Conv2d = get_same_padding_conv2d(image_size=image_size)'], 'executed_lines': {68, 69, 70, 51, 52, 53, 54, 55, 56, 59, 60, 61}, 'executed_function_lines': {199}, 'extra_calls': 0}

{'function_name': 'get_same_padding_conv2d', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 199, 'args': {'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['if image_size is None:', 'return partial(Conv2dStaticSamePadding, image_size=image_size)'], 'executed_lines': {209, 212}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'functools.partial'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 50, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'block_args': {'type': "<class 'efficientnet_pytorch.utils.BlockArgs'>", 'shape': (8,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}, 'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['super().__init__()', 'self._block_args = block_args', "self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow", 'self._bn_eps = global_params.batch_norm_epsilon', 'self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)', 'self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect', 'inp = self._block_args.input_filters  # number of input channels', 'oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels', 'if self._block_args.expand_ratio != 1:', 'k = self._block_args.kernel_size', 's = self._block_args.stride', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._depthwise_conv = Conv2d(', 'in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise', 'kernel_size=k, stride=s, bias=False)'], 'executed_lines': {68, 69, 70, 71, 72, 73, 51, 52, 53, 54, 55, 56, 59, 60, 61}, 'executed_function_lines': {255, 199}, 'extra_calls': 0}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 255, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.Conv2dStaticSamePadding'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'out_channels': {'type': "<class 'int'>", 'shape': None}, 'kernel_size': {'type': "<class 'int'>", 'shape': None}, 'stride': {'type': "<class 'list'>", 'shape': (1,)}, 'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)', 'self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2', 'assert image_size is not None', 'ih, iw = (image_size, image_size) if isinstance(image_size, int) else image_size', 'kh, kw = self.weight.size()[-2:]', 'sh, sw = self.stride', 'oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)', 'pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)', 'pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)', 'if pad_h > 0 or pad_w > 0:', 'self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,', 'pad_h // 2, pad_h - pad_h // 2))'], 'executed_lines': {256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 50, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'block_args': {'type': "<class 'efficientnet_pytorch.utils.BlockArgs'>", 'shape': (8,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}, 'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['super().__init__()', 'self._block_args = block_args', "self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow", 'self._bn_eps = global_params.batch_norm_epsilon', 'self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)', 'self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect', 'inp = self._block_args.input_filters  # number of input channels', 'oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels', 'if self._block_args.expand_ratio != 1:', 'k = self._block_args.kernel_size', 's = self._block_args.stride', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._depthwise_conv = Conv2d(', 'in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise', 'kernel_size=k, stride=s, bias=False)', 'self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)', 'image_size = calculate_output_image_size(image_size, s)'], 'executed_lines': {68, 69, 70, 71, 72, 73, 74, 75, 51, 52, 53, 54, 55, 56, 59, 60, 61}, 'executed_function_lines': {255, 174, 199}, 'extra_calls': 0}

{'function_name': 'calculate_output_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 174, 'args': {'input_image_size': {'type': "<class 'list'>", 'shape': (2,)}, 'stride': {'type': "<class 'list'>", 'shape': (1,)}}, 'lines': ['if input_image_size is None:', 'image_height, image_width = get_width_and_height_from_size(input_image_size)'], 'executed_lines': {185, 187}, 'executed_function_lines': {157}, 'extra_calls': 0}

{'function_name': 'get_width_and_height_from_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 157, 'args': {'x': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['if isinstance(x, int):', 'if isinstance(x, list) or isinstance(x, tuple):', 'return x'], 'executed_lines': {168, 169, 166}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (2,)}}

{'function_name': 'calculate_output_image_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 174, 'args': {'input_image_size': {'type': "<class 'list'>", 'shape': (2,)}, 'stride': {'type': "<class 'list'>", 'shape': (1,)}}, 'lines': ['if input_image_size is None:', 'image_height, image_width = get_width_and_height_from_size(input_image_size)', 'stride = stride if isinstance(stride, int) else stride[0]', 'image_height = int(math.ceil(image_height / stride))', 'image_width = int(math.ceil(image_width / stride))', 'return [image_height, image_width]'], 'executed_lines': {185, 187, 188, 189, 190, 191}, 'executed_function_lines': {157}, 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (2,)}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 50, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'block_args': {'type': "<class 'efficientnet_pytorch.utils.BlockArgs'>", 'shape': (8,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}, 'image_size': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['super().__init__()', 'self._block_args = block_args', "self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow", 'self._bn_eps = global_params.batch_norm_epsilon', 'self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)', 'self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect', 'inp = self._block_args.input_filters  # number of input channels', 'oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels', 'if self._block_args.expand_ratio != 1:', 'k = self._block_args.kernel_size', 's = self._block_args.stride', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._depthwise_conv = Conv2d(', 'in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise', 'kernel_size=k, stride=s, bias=False)', 'self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)', 'image_size = calculate_output_image_size(image_size, s)', 'if self.has_se:', 'Conv2d = get_same_padding_conv2d(image_size=(1, 1))', 'if image_size is None:', 'return partial(Conv2dStaticSamePadding, image_size=image_size)', 'num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))', 'self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)', 'super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)', 'self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2', 'assert image_size is not None', 'ih, iw = (image_size, image_size) if isinstance(image_size, int) else image_size', 'kh, kw = self.weight.size()[-2:]', 'sh, sw = self.stride', 'oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)', 'pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)', 'pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)', 'if pad_h > 0 or pad_w > 0:', 'self.static_padding = nn.Identity()', 'self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)', 'final_oup = self._block_args.output_filters', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)', 'self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)', 'self._swish = MemoryEfficientSwish()'], 'executed_lines': {256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 271, 51, 52, 53, 54, 55, 56, 59, 60, 61, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 209, 81, 82, 212, 85, 86, 87, 88, 89}, 'executed_function_lines': {255, 174, 199}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)', 'self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'image_size = calculate_output_image_size(image_size, 2)', 'self._blocks = nn.ModuleList([])', 'for block_args in self._blocks_args:', 'block_args = block_args._replace(', 'input_filters=round_filters(block_args.input_filters, self._global_params),', 'multiplier = global_params.width_coefficient', 'if not multiplier:', 'divisor = global_params.depth_divisor', 'min_depth = global_params.min_depth', 'filters *= multiplier', 'min_depth = min_depth or divisor  # pay attention to this line when using min_depth', 'new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)', 'if new_filters < 0.9 * filters:  # prevent rounding by more than 10%', 'return int(new_filters)', 'output_filters=round_filters(block_args.output_filters, self._global_params),', 'num_repeat=round_repeats(block_args.num_repeat, self._global_params)', 'self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))', 'image_size = calculate_output_image_size(image_size, block_args.stride)', 'if input_image_size is None:'], 'executed_lines': {164, 165, 166, 167, 168, 171, 172, 175, 176, 179, 180, 181, 182, 183, 185, 186, 187, 190, 191, 192, 193, 197, 198, 94, 95, 100, 101, 102, 103, 105, 106, 108}, 'executed_function_lines': {199, 174, 111, 50, 83, 157, 255}, 'extra_calls': 1, 'return_value': {'type': "<class 'int'>", 'shape': None}}

{'function_name': 'get_width_and_height_from_size', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 157, 'args': {'x': {'type': "<class 'list'>", 'shape': (2,)}}, 'lines': ['if isinstance(x, int):', 'if isinstance(x, list) or isinstance(x, tuple):', 'return x'], 'executed_lines': {168, 169, 166}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'list'>", 'shape': (2,)}}

{'function_name': '__init__', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 163, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'blocks_args': {'type': "<class 'list'>", 'shape': (7,)}, 'global_params': {'type': "<class 'efficientnet_pytorch.utils.GlobalParams'>", 'shape': (11,)}}, 'lines': ['super().__init__()', "assert isinstance(blocks_args, list), 'blocks_args should be a list'", "assert len(blocks_args) > 0, 'block args must be greater than 0'", 'self._global_params = global_params', 'self._blocks_args = blocks_args', 'bn_mom = 1 - self._global_params.batch_norm_momentum', 'bn_eps = self._global_params.batch_norm_epsilon', 'image_size = global_params.image_size', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'in_channels = 3  # rgb', 'out_channels = round_filters(32, self._global_params)  # number of output channels', 'self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)', 'self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'image_size = calculate_output_image_size(image_size, 2)', 'self._blocks = nn.ModuleList([])', 'for block_args in self._blocks_args:', 'block_args = block_args._replace(', 'input_filters=round_filters(block_args.input_filters, self._global_params),', 'multiplier = global_params.width_coefficient', 'if not multiplier:', 'divisor = global_params.depth_divisor', 'min_depth = global_params.min_depth', 'filters *= multiplier', 'min_depth = min_depth or divisor  # pay attention to this line when using min_depth', 'new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)', 'if new_filters < 0.9 * filters:  # prevent rounding by more than 10%', 'return int(new_filters)', 'output_filters=round_filters(block_args.output_filters, self._global_params),', 'num_repeat=round_repeats(block_args.num_repeat, self._global_params)', 'self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))', 'image_size = calculate_output_image_size(image_size, block_args.stride)', 'if input_image_size is None:', 'stride = stride if isinstance(stride, int) else stride[0]', 'image_height = int(math.ceil(image_height / stride))', 'if block_args.num_repeat > 1:  # modify block_args to keep same output size', 'for _ in range(block_args.num_repeat - 1):', 'multiplier = global_params.depth_coefficient', 'if not multiplier:', 'return int(math.ceil(multiplier * repeats))', 'super().__init__()', 'self._block_args = block_args', "self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow", 'self._bn_eps = global_params.batch_norm_epsilon', 'self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)', 'self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect', 'inp = self._block_args.input_filters  # number of input channels', 'oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels', 'if self._block_args.expand_ratio != 1:', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'if image_size is None:', 'return partial(Conv2dStaticSamePadding, image_size=image_size)', 'self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)', 'super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)', 'self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2', 'assert image_size is not None', 'ih, iw = (image_size, image_size) if isinstance(image_size, int) else image_size', 'kh, kw = self.weight.size()[-2:]', 'sh, sw = self.stride', 'oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)', 'pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)', 'pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)', 'if pad_h > 0 or pad_w > 0:', 'self.static_padding = nn.Identity()', 'self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)', 'k = self._block_args.kernel_size', 's = self._block_args.stride', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._depthwise_conv = Conv2d(', 'in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise', 'kernel_size=k, stride=s, bias=False)', 'self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,', 'pad_h // 2, pad_h - pad_h // 2))', 'self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)', 'image_size = calculate_output_image_size(image_size, s)', 'return x', 'if self.has_se:', 'Conv2d = get_same_padding_conv2d(image_size=(1, 1))', 'num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))', 'self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)', 'self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)', 'final_oup = self._block_args.output_filters', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)', 'self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)', 'self._swish = MemoryEfficientSwish()', 'block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)', 'self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))', 'in_channels = block_args.output_filters  # output of final block', 'out_channels = round_filters(1280, self._global_params)', 'Conv2d = get_same_padding_conv2d(image_size=image_size)', 'self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)', 'self._avg_pooling = nn.AdaptiveAvgPool2d(1)', 'if self._global_params.include_top:', 'self._dropout = nn.Dropout(self._global_params.dropout_rate)', 'self._fc = nn.Linear(out_channels, self._global_params.num_classes)', 'self._swish = MemoryEfficientSwish()'], 'executed_lines': {51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 94, 95, 100, 101, 102, 103, 105, 106, 108, 122, 123, 126, 164, 165, 166, 167, 168, 169, 171, 172, 175, 176, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 197, 198, 199, 200, 201, 202, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 219, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271}, 'executed_function_lines': {199, 174, 111, 50, 83, 157, 255}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'from_name', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 323, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['cls._check_model_name_is_valid(model_name)', 'blocks_args, global_params = get_model_params(model_name, override_params)', 'model = cls(blocks_args, global_params)', 'model._change_in_channels(in_channels)'], 'executed_lines': {344, 345, 342, 343}, 'executed_function_lines': {163, 531, 397, 410}, 'extra_calls': 0}

{'function_name': '_change_in_channels', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 410, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if in_channels != 3:'], 'executed_lines': {416}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'from_name', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 323, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['cls._check_model_name_is_valid(model_name)', 'blocks_args, global_params = get_model_params(model_name, override_params)', 'model = cls(blocks_args, global_params)', 'model._change_in_channels(in_channels)', 'return model'], 'executed_lines': {342, 343, 344, 345, 346}, 'executed_function_lines': {163, 531, 397, 410}, 'extra_calls': 0, 'return_value': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}}

{'function_name': 'from_pretrained', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 348, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'weights_path': {'type': "<class 'NoneType'>", 'shape': None}, 'advprop': {'type': "<class 'bool'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['model = cls.from_name(model_name, num_classes=num_classes, **override_params)', 'load_pretrained_weights(model, model_name, weights_path=weights_path,', 'load_fc=(num_classes == 1000), advprop=advprop)'], 'executed_lines': {377, 378, 379}, 'executed_function_lines': {584, 323}, 'extra_calls': 0}

{'function_name': 'load_pretrained_weights', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 584, 'args': {'model': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'weights_path': {'type': "<class 'NoneType'>", 'shape': None}, 'load_fc': {'type': "<class 'bool'>", 'shape': None}, 'advprop': {'type': "<class 'bool'>", 'shape': None}, 'verbose': {'type': "<class 'bool'>", 'shape': None}}, 'lines': ['if isinstance(weights_path, str):', 'url_map_ = url_map_advprop if advprop else url_map', 'state_dict = model_zoo.load_url(url_map_[model_name])', 'if load_fc:', 'ret = model.load_state_dict(state_dict, strict=False)', "assert not ret.missing_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)", "assert not ret.unexpected_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.unexpected_keys)", 'if verbose:', "print('Loaded pretrained weights for {}'.format(model_name))"], 'executed_lines': {613, 615, 616, 597, 601, 602, 604, 605, 606}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'from_pretrained', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 348, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'weights_path': {'type': "<class 'NoneType'>", 'shape': None}, 'advprop': {'type': "<class 'bool'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['model = cls.from_name(model_name, num_classes=num_classes, **override_params)', 'load_pretrained_weights(model, model_name, weights_path=weights_path,', 'load_fc=(num_classes == 1000), advprop=advprop)', 'model._change_in_channels(in_channels)'], 'executed_lines': {377, 378, 379, 380}, 'executed_function_lines': {584, 410, 323}, 'extra_calls': 0}

{'function_name': '_change_in_channels', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 410, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['if in_channels != 3:'], 'executed_lines': {416}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

{'function_name': 'from_pretrained', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 348, 'args': {'cls': {'type': "<class 'type'>", 'shape': None}, 'model_name': {'type': "<class 'str'>", 'shape': (15,)}, 'weights_path': {'type': "<class 'NoneType'>", 'shape': None}, 'advprop': {'type': "<class 'bool'>", 'shape': None}, 'in_channels': {'type': "<class 'int'>", 'shape': None}, 'num_classes': {'type': "<class 'int'>", 'shape': None}}, 'lines': ['model = cls.from_name(model_name, num_classes=num_classes, **override_params)', 'load_pretrained_weights(model, model_name, weights_path=weights_path,', 'load_fc=(num_classes == 1000), advprop=advprop)', 'model._change_in_channels(in_channels)', 'return model'], 'executed_lines': {377, 378, 379, 380, 381}, 'executed_function_lines': {584, 410, 323}, 'extra_calls': 0, 'return_value': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)', 'tf.config.experimental_run_functions_eagerly(True)', 'MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]', 'STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]', 'CROP_PADDING = 32', 'image_size = 224', 'def _decode_and_center_crop(image_bytes, image_size):', "tf_img_bytes = tf.io.read_file('examples/simple/img.jpg')", 'tf_img = _decode_and_center_crop(tf_img_bytes, image_size)', 'tf_img = tf.compat.v1.image.resize_bicubic([tf_img], [image_size, image_size])[0] # ok it matches up to here', 'use_bfloat16 = 224 # bug in the original repo!', 'tf_img = tf.image.convert_image_dtype(tf_img, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)', 'tf_img = tf.cast(tf_img, tf.float32)', 'tf_img = (tf_img - MEAN_RGB) / (STDDEV_RGB)  # this is exactly the input to the model', 'img = torch.from_numpy(tf_img.numpy()).unsqueeze(0).permute((0,3,1,2))', "labels_map = json.load(open('examples/simple/labels_map.txt'))", 'labels_map = [labels_map[str(i)] for i in range(1000)]', 'model = EfficientNet.from_pretrained(model_name)', 'model.eval()', 'with torch.no_grad():', 'logits = model(img)'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10, 15, 18, 19, 20, 21, 24, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55, 56, 57, 58}, 'executed_function_lines': {1, 303, 52, 24, 348, 383}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 303, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self.extract_features(inputs)'], 'executed_lines': {314}, 'executed_function_lines': {278}, 'extra_calls': 0}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))'], 'executed_lines': {289}, 'executed_function_lines': {273}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 273, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.Conv2dStaticSamePadding'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x'], 'executed_lines': {274, 275, 276}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))'], 'executed_lines': {289}, 'executed_function_lines': {273, 79}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 79, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.MemoryEfficientSwish'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['return SwishImplementation.apply(x)'], 'executed_lines': {80}, 'executed_function_lines': {65}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 65, 'args': {'ctx': {'type': "<class 'torch.autograd.function.SwishImplementationBackward'>", 'shape': None}, 'i': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result'], 'executed_lines': {67, 68, 69}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 79, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.MemoryEfficientSwish'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['return SwishImplementation.apply(x)'], 'executed_lines': {80}, 'executed_function_lines': {65}, 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))', 'for idx, block in enumerate(self._blocks):', 'drop_connect_rate = self._global_params.drop_connect_rate', 'if drop_connect_rate:', 'drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate', 'x = block(x, drop_connect_rate=drop_connect_rate)'], 'executed_lines': {289, 292, 293, 294, 295, 296}, 'executed_function_lines': {273, 91, 79}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 91, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}}, 'lines': ['x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._depthwise_conv(x)'], 'executed_lines': {104, 109, 103}, 'executed_function_lines': {273}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 273, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.Conv2dStaticSamePadding'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x'], 'executed_lines': {274, 275, 276}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 91, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}}, 'lines': ['x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._depthwise_conv(x)', 'x = self._bn1(x)', 'x = self._swish(x)'], 'executed_lines': {103, 104, 109, 110, 111}, 'executed_function_lines': {273, 79}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 79, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.MemoryEfficientSwish'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['return SwishImplementation.apply(x)'], 'executed_lines': {80}, 'executed_function_lines': {65}, 'extra_calls': 0}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 65, 'args': {'ctx': {'type': "<class 'torch.autograd.function.SwishImplementationBackward'>", 'shape': None}, 'i': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result'], 'executed_lines': {67, 68, 69}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 79, 'args': {'self': {'type': "<class 'efficientnet_pytorch.utils.MemoryEfficientSwish'>", 'shape': None}, 'x': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}, 'lines': ['return SwishImplementation.apply(x)'], 'executed_lines': {80}, 'executed_function_lines': {65}, 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 91, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}}, 'lines': ['x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._depthwise_conv(x)', 'x = self._bn1(x)', 'x = self._swish(x)', 'if self.has_se:', 'x_squeezed = F.adaptive_avg_pool2d(x, 1)', 'x_squeezed = self._se_reduce(x_squeezed)', 'x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x', 'x_squeezed = self._swish(x_squeezed)', 'return SwishImplementation.apply(x)'], 'executed_lines': {103, 104, 109, 110, 111, 80, 114, 115, 116, 274, 275, 276, 117}, 'executed_function_lines': {65, 273, 79}, 'extra_calls': 1, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 8, 1, 1])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 65, 'args': {'ctx': {'type': "<class 'torch.autograd.function.SwishImplementationBackward'>", 'shape': None}, 'i': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 8, 1, 1])}}, 'lines': ['result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result'], 'executed_lines': {67, 68, 69}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 8, 1, 1])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 91, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.MBConvBlock'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 32, 112, 112])}, 'drop_connect_rate': {'type': "<class 'float'>", 'shape': None}}, 'lines': ['x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._depthwise_conv(x)', 'x = self._bn1(x)', 'x = self._swish(x)', 'if self.has_se:', 'x_squeezed = F.adaptive_avg_pool2d(x, 1)', 'x_squeezed = self._se_reduce(x_squeezed)', 'x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x', 'x_squeezed = self._swish(x_squeezed)', 'return SwishImplementation.apply(x)', 'x_squeezed = self._se_expand(x_squeezed)', 'x = torch.sigmoid(x_squeezed) * x', 'x = self._project_conv(x)', 'x = self._bn2(x)', 'input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters', 'if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:', 'return x'], 'executed_lines': {132, 274, 275, 276, 80, 103, 104, 109, 110, 111, 114, 115, 116, 117, 118, 119, 122, 123, 126, 127}, 'executed_function_lines': {65, 273, 79}, 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 16, 112, 112])}}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))', 'for idx, block in enumerate(self._blocks):', 'drop_connect_rate = self._global_params.drop_connect_rate', 'if drop_connect_rate:', 'drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate', 'x = block(x, drop_connect_rate=drop_connect_rate)', 'x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._expand_conv(inputs)', 'x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x', 'x = self._bn0(x)', 'x = self._swish(x)', 'return SwishImplementation.apply(x)'], 'executed_lines': {289, 292, 293, 294, 295, 296, 103, 104, 105, 106, 107, 80, 274, 275, 276}, 'executed_function_lines': {65, 273, 91, 79}, 'extra_calls': 2, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 96, 112, 112])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 65, 'args': {'ctx': {'type': "<class 'torch.autograd.function.SwishImplementationBackward'>", 'shape': None}, 'i': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 96, 112, 112])}}, 'lines': ['result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result'], 'executed_lines': {67, 68, 69}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 96, 112, 112])}}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))', 'for idx, block in enumerate(self._blocks):', 'drop_connect_rate = self._global_params.drop_connect_rate', 'if drop_connect_rate:', 'drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate', 'x = block(x, drop_connect_rate=drop_connect_rate)', 'x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._expand_conv(inputs)', 'x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x', 'x = self._bn0(x)', 'x = self._swish(x)', 'return SwishImplementation.apply(x)', 'x = self._depthwise_conv(x)', 'x = self._bn1(x)', 'x = self._swish(x)', 'result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result', 'if self.has_se:', 'x_squeezed = F.adaptive_avg_pool2d(x, 1)', 'x_squeezed = self._se_reduce(x_squeezed)', 'x_squeezed = self._swish(x_squeezed)', 'x_squeezed = self._se_expand(x_squeezed)', 'x = torch.sigmoid(x_squeezed) * x', 'x = self._project_conv(x)', 'x = self._bn2(x)', 'input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters', 'if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:', 'return x', 'if drop_connect_rate:', 'x = drop_connect(x, p=drop_connect_rate, training=self.training)'], 'executed_lines': {129, 130, 132, 274, 275, 276, 289, 292, 293, 294, 295, 296, 67, 68, 69, 80, 103, 104, 105, 106, 107, 109, 110, 111, 114, 115, 116, 117, 118, 119, 122, 123, 126, 127}, 'executed_function_lines': {65, 129, 79, 273, 91}, 'extra_calls': 1, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 24, 56, 56])}}

{'function_name': 'drop_connect', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/utils.py', 'lineno': 129, 'args': {'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 24, 56, 56])}, 'p': {'type': "<class 'float'>", 'shape': None}, 'training': {'type': "<class 'bool'>", 'shape': None}}, 'lines': ["assert 0 <= p <= 1, 'p must be in range of [0,1]'", 'if not training:', 'return inputs'], 'executed_lines': {140, 142, 143}, 'executed_function_lines': set(), 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 24, 56, 56])}}

{'function_name': 'extract_features', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 278, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self._swish(self._bn0(self._conv_stem(inputs)))', 'for idx, block in enumerate(self._blocks):', 'drop_connect_rate = self._global_params.drop_connect_rate', 'if drop_connect_rate:', 'drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate', 'x = block(x, drop_connect_rate=drop_connect_rate)', 'x = inputs', 'if self._block_args.expand_ratio != 1:', 'x = self._expand_conv(inputs)', 'x = self.static_padding(x)', 'x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)', 'return x', 'x = self._bn0(x)', 'x = self._swish(x)', 'return SwishImplementation.apply(x)', 'x = self._depthwise_conv(x)', 'x = self._bn1(x)', 'x = self._swish(x)', 'result = i * torch.sigmoid(i)', 'ctx.save_for_backward(i)', 'return result', 'if self.has_se:', 'x_squeezed = F.adaptive_avg_pool2d(x, 1)', 'x_squeezed = self._se_reduce(x_squeezed)', 'x_squeezed = self._swish(x_squeezed)', 'x_squeezed = self._se_expand(x_squeezed)', 'x = torch.sigmoid(x_squeezed) * x', 'x = self._project_conv(x)', 'x = self._bn2(x)', 'input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters', 'if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:', 'return x', 'if drop_connect_rate:', 'x = drop_connect(x, p=drop_connect_rate, training=self.training)', 'x = x + inputs  # skip connection', "assert 0 <= p <= 1, 'p must be in range of [0,1]'", 'if not training:', 'return inputs', 'x = self._swish(self._bn1(self._conv_head(x)))', 'return x'], 'executed_lines': {129, 130, 131, 132, 140, 142, 143, 274, 275, 276, 289, 292, 293, 294, 295, 296, 299, 301, 67, 68, 69, 80, 103, 104, 105, 106, 107, 109, 110, 111, 114, 115, 116, 117, 118, 119, 122, 123, 126, 127}, 'executed_function_lines': {65, 129, 79, 273, 91}, 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 1280, 7, 7])}}

{'function_name': 'forward', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/efficientnet_pytorch/model.py', 'lineno': 303, 'args': {'self': {'type': "<class 'efficientnet_pytorch.model.EfficientNet'>", 'shape': None}, 'inputs': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 3, 224, 224])}}, 'lines': ['x = self.extract_features(inputs)', 'x = self._avg_pooling(x)', 'if self._global_params.include_top:', 'x = x.flatten(start_dim=1)', 'x = self._dropout(x)', 'x = self._fc(x)', 'return x'], 'executed_lines': {320, 321, 314, 316, 317, 318, 319}, 'executed_function_lines': {278}, 'extra_calls': 0, 'return_value': {'type': "<class 'torch.Tensor'>", 'shape': torch.Size([1, 1000])}}

{'function_name': '<module>', 'filename': '/media/sarthak/storage/Pipeline_Generator/EfficientNet-PyTorch/test.py', 'lineno': 1, 'args': {}, 'lines': ['import json', 'from PIL import Image', 'import torch', 'import tensorflow as tf', 'from efficientnet_pytorch import EfficientNet', "model_name = 'efficientnet-b0'", 'image_size = EfficientNet.get_image_size(model_name)', 'tf.config.experimental_run_functions_eagerly(True)', 'MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]', 'STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]', 'CROP_PADDING = 32', 'image_size = 224', 'def _decode_and_center_crop(image_bytes, image_size):', "tf_img_bytes = tf.io.read_file('examples/simple/img.jpg')", 'tf_img = _decode_and_center_crop(tf_img_bytes, image_size)', 'tf_img = tf.compat.v1.image.resize_bicubic([tf_img], [image_size, image_size])[0] # ok it matches up to here', 'use_bfloat16 = 224 # bug in the original repo!', 'tf_img = tf.image.convert_image_dtype(tf_img, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)', 'tf_img = tf.cast(tf_img, tf.float32)', 'tf_img = (tf_img - MEAN_RGB) / (STDDEV_RGB)  # this is exactly the input to the model', 'img = torch.from_numpy(tf_img.numpy()).unsqueeze(0).permute((0,3,1,2))', "labels_map = json.load(open('examples/simple/labels_map.txt'))", 'labels_map = [labels_map[str(i)] for i in range(1000)]', 'model = EfficientNet.from_pretrained(model_name)', 'model.eval()', 'with torch.no_grad():', 'logits = model(img)', 'print(logits)'], 'executed_lines': {1, 2, 4, 5, 7, 9, 10, 15, 18, 19, 20, 21, 24, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55, 56, 57, 58, 59}, 'executed_function_lines': {1, 303, 52, 24, 348, 383}, 'extra_calls': 0, 'return_value': {'type': "<class 'NoneType'>", 'shape': None}}

